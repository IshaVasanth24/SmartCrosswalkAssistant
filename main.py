import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
from pathlib import Path
from gtts import gTTS
import os
import pygame
import time
import tempfile
import threading

# Initialize pygame mixer for audio playback
pygame.mixer.init()

st.title("ЁЯЪж Smart Pedestrian Assistant for Visually Impaired")

# Indian language selection
LANGUAGES = {
    "English": "en",
    "Hindi": "hi",
    "Kannada": "kn",
    "Tamil": "ta",
    "Telugu": "te",
    "Konkani": "kok",
    "Tulu": None
}

selected_lang = st.selectbox("Select Alert Language", list(LANGUAGES.keys()))
lang_code = LANGUAGES[selected_lang]

# Load YOLOv11 model
@st.cache_resource
def load_model():
    return YOLO("yolov11s_blindaid_best.pt")

model = load_model()

# Indian language alert messages
ALERT_MESSAGES = {
    "en": {
        "moving": "Warning! Vehicles are moving. Do not cross.",
        "stopped": "Caution. {count} vehicles detected but stopped. Proceed with care.",
        "clear": "The path is clear. Safe to cross now."
    },
    "hi": {
        "moving": "рдЪреЗрддрд╛рд╡рдиреА! рд╡рд╛рд╣рди рдЪрд▓ рд░рд╣реЗ рд╣реИрдВред рдкрд╛рд░ рди рдХрд░реЗрдВред",
        "stopped": "рд╕рд╛рд╡рдзрд╛рдиред {count} рд╡рд╛рд╣рдиреЛрдВ рдХрд╛ рдкрддрд╛ рдЪрд▓рд╛ рд╣реИ рд▓реЗрдХрд┐рди рд╡реЗ рд░реБрдХреЗ рд╣реБрдП рд╣реИрдВред рд╕рд╛рд╡рдзрд╛рдиреА рд╕реЗ рдЖрдЧреЗ рдмрдврд╝реЗрдВред",
        "clear": "рд░рд╛рд╕реНрддрд╛ рд╕рд╛рдл рд╣реИред рдЕрдм рд╕реБрд░рдХреНрд╖рд┐рдд рд░реВрдк рд╕реЗ рдкрд╛рд░ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред"
    },
    "kn": {
        "moving": "р▓Ор▓Ър│Нр▓Ър▓░р▓┐р▓Хр│Ж! р▓╡р▓╛р▓╣р▓ир▓Чр▓│р│Б р▓Ър▓▓р▓┐р▓╕р│Бр▓др│Нр▓др▓┐р▓╡р│Ж. р▓жр▓╛р▓Яр▓мр│Зр▓бр▓┐.",
        "stopped": "р▓Ьр▓╛р▓Чр▓░р│Вр▓Хр▓░р▓╛р▓Чр▓┐р▓░р▓┐. {count} р▓╡р▓╛р▓╣р▓ир▓Чр▓│р│Б р▓Хр▓Вр▓бр│Бр▓мр▓Вр▓жр▓┐р▓╡р│Ж р▓Жр▓жр▓░р│Ж р▓ир▓┐р▓▓р│Нр▓▓р▓┐р▓╕р▓▓р▓╛р▓Чр▓┐р▓жр│Ж. р▓Ьр▓╛р▓Чр▓░р│Вр▓Хр▓др│Жр▓пр▓┐р▓Вр▓ж р▓ор│Бр▓Вр▓жр│Бр▓╡р▓░р▓┐р▓пр▓┐р▓░р▓┐.",
        "clear": "р▓ор▓╛р▓░р│Нр▓Ч р▓╕р│Нр▓кр▓╖р│Нр▓Яр▓╡р▓╛р▓Чр▓┐р▓жр│Ж. р▓Ир▓Ч р▓╕р│Бр▓░р▓Хр│Нр▓╖р▓┐р▓др▓╡р▓╛р▓Чр▓┐ р▓жр▓╛р▓Яр▓мр▓╣р│Бр▓жр│Б."
    },
    "ta": {
        "moving": "роОроЪрпНроЪро░ро┐роХрпНроХрпИ! ро╡ро╛роХройроЩрпНроХро│рпН роироХро░рпБроорпН. роХроЯроХрпНроХ ро╡рпЗрогрпНроЯро╛роорпН.",
        "stopped": "роОроЪрпНроЪро░ро┐роХрпНроХрпИ. {count} ро╡ро╛роХройроЩрпНроХро│рпН роХрогрпНроЯро▒ро┐ропрокрпНрокроЯрпНроЯрой роЖройро╛ро▓рпН роиро┐ро▒рпБродрпНродрокрпНрокроЯрпНроЯрой. роХро╡ройродрпНродрпБроЯройрпН родрпКроЯро░ро╡рпБроорпН.",
        "clear": "рокро╛родрпИ родрпЖро│ро┐ро╡ро╛роХ роЙро│рпНро│родрпБ. роЗрокрпНрокрпЛродрпБ рокро╛родрпБроХро╛рокрпНрокро╛роХ роХроЯроХрпНроХро▓ро╛роорпН."
    },
    "te": {
        "moving": "р░╣р▒Жр░Ър▒Нр░Ър░░р░┐р░Х! р░╡р░╛р░╣р░ир░╛р░▓р▒Б р░Хр░жр▒Бр░▓р▒Бр░др▒Бр░ир▒Нр░ир░╛р░пр░┐. р░жр░╛р░Яр░╡р░жр▒Нр░жр▒Б.",
        "stopped": "р░Ьр░╛р░Чр▒Нр░░р░др▒Нр░д. {count} р░╡р░╛р░╣р░ир░╛р░▓р▒Б р░Хр░ир▒Бр░Чр▒Кр░ир░мр░бр▒Нр░бр░╛р░пр░┐ р░Хр░╛р░ир▒А р░Жр░кр░мр░бр▒Нр░бр░╛р░пр░┐. р░Ьр░╛р░Чр▒Нр░░р░др▒Нр░др░Чр░╛ р░ор▒Бр░Вр░жр▒Бр░Хр▒Б р░╕р░╛р░Чр░Вр░бр░┐.",
        "clear": "р░ор░╛р░░р▒Нр░Чр░В р░╕р▒Нр░кр░╖р▒Нр░Яр░Вр░Чр░╛ р░Йр░Вр░жр░┐. р░Зр░кр▒Нр░кр▒Бр░бр▒Б р░╕р▒Бр░░р░Хр▒Нр░╖р░┐р░др░Вр░Чр░╛ р░жр░╛р░Яр░╡р░Ър▒Нр░Ър▒Б."
    },
    "kok": {
        "moving": "Xetavanni! Vaahan chalta. Poddunk naka.",
        "stopped": "Savdhani. {count} vaahan mell'l'le ani thamble asat. Savdhanean voch.",
        "clear": "Marg mullav. Ata surakshit poddunk zai."
    },
    None: {
        "moving": "Tulu: Warning! Vehicles moving. Barpandhe.",
        "stopped": "Tulu: {count} vehicles stopped. Savdhana.",
        "clear": "Tulu: Safe to cross. Barpuji."
    }
}

# Function to handle audio playback with temp files
def speak(text, lang):
    try:
        # Create a temporary file
        with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as tmp_file:
            temp_path = tmp_file.name
        
        # For Tulu, use Kannada TTS as fallback
        tts_lang = "kn" if lang is None else lang
        
        # For Konkani in Roman script, use English TTS
        if lang == "kok":
            tts_lang = "en"
            
        # Generate TTS
        tts = gTTS(text=text, lang=tts_lang, slow=False)
        tts.save(temp_path)
        
        # Wait if another audio is playing
        while pygame.mixer.get_busy():
            time.sleep(0.1)
            
        # Play the audio
        pygame.mixer.music.load(temp_path)
        pygame.mixer.music.play()
        
        # Clean up in a separate thread after playback completes
        def cleanup():
            start_time = time.time()
            while pygame.mixer.get_busy() and (time.time() - start_time) < 5:  # Timeout after 5 seconds
                time.sleep(0.1)
            try:
                if os.path.exists(temp_path):
                    os.remove(temp_path)
            except:
                pass
        
        threading.Thread(target=cleanup, daemon=True).start()
        
    except Exception as e:
        st.warning(f"Audio error: {e}")
        try:
            if os.path.exists(temp_path):
                os.remove(temp_path)
        except:
            pass

# Track vehicle positions across frames
def detect_and_track_motion(frame, prev_tracks):
    results = model(frame, verbose=False)[0]  # Get prediction result

    motion_detected = False
    current_tracks = {}
    vehicle_count = 0

    # Loop through all detections
    for box in results.boxes:
        cls_id = int(box.cls[0])
        label = model.names[cls_id]

        if label.lower() not in ["car", "truck", "bus", "motorcycle"]:  # Filter only vehicles
            continue

        vehicle_count += 1
        x1, y1, x2, y2 = map(int, box.xyxy[0])
        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
        current_tracks[(cx, cy)] = (x1, y1, x2, y2)

        # Check movement by comparing with previous frame
        if prev_tracks:
            closest = min(prev_tracks.keys(), key=lambda p: (p[0] - cx)**2 + (p[1] - cy)**2, default=None)
            if closest:
                old_cx, old_cy = closest
                distance = ((old_cx - cx) ** 2 + (old_cy - cy) ** 2) ** 0.5
                if distance > 20:  # Movement threshold
                    motion_detected = True

    return current_tracks, motion_detected, vehicle_count

# Upload video
uploaded_file = st.file_uploader("Upload a video", type=["mp4", "avi", "mov"])

if uploaded_file:
    # Create temp file
    temp_dir = tempfile.mkdtemp()
    video_path = os.path.join(temp_dir, "temp_video.mp4")
    with open(video_path, "wb") as f:
        f.write(uploaded_file.read())

    cap = cv2.VideoCapture(video_path)
    stframe = st.empty()

    prev_tracks = {}
    last_alert_time = 0
    last_status = ""
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        frame = cv2.resize(frame, (640, 360))  # Resize for speed

        current_tracks, motion, vehicle_count = detect_and_track_motion(frame, prev_tracks)
        prev_tracks = current_tracks

        # Draw bounding boxes
        for (cx, cy), (x1, y1, x2, y2) in current_tracks.items():
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.circle(frame, (cx, cy), 4, (0, 0, 255), -1)

        # Decision logic
        if motion:
            status_text = "ЁЯЪл Don't Cross - Vehicles Moving"
            status_audio = ALERT_MESSAGES[lang_code]["moving"] if lang_code else ALERT_MESSAGES[None]["moving"]
            color = (0, 0, 255)
        elif current_tracks:
            status_text = "тЬЕ Safe to Walk - Vehicles Stopped"
            status_audio = (ALERT_MESSAGES[lang_code]["stopped"] if lang_code else ALERT_MESSAGES[None]["stopped"]).format(count=vehicle_count)
            color = (0, 255, 0)
        else:
            status_text = "тЬЕ Safe to Walk - No Vehicles"
            status_audio = ALERT_MESSAGES[lang_code]["clear"] if lang_code else ALERT_MESSAGES[None]["clear"]
            color = (0, 255, 0)

        # Update status text on frame
        cv2.putText(frame, status_text, (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)

        # Audio alerts (throttled to avoid too frequent playback)
        current_time = time.time()
        if (status_audio != last_status or current_time - last_alert_time > 5) and not pygame.mixer.get_busy():
            speak(status_audio, lang_code)
            last_alert_time = current_time
            last_status = status_audio

        # Show in Streamlit
        stframe.image(frame, channels="BGR", use_container_width=True)

    cap.release()
    
    # Clean up temporary video file
    try:
        os.remove(video_path)
        os.rmdir(temp_dir)
    except:
        pass